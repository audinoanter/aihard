<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><link rel="icon" href="favicon.ico"><title>AI HARD - Explainer Dashboard, a tool to answer how the machine learning models works</title><link href="css/about-us~f71cff67.b5ffa400.css" rel="prefetch"><link href="css/chunk-21989e4a.4f45a114.css" rel="prefetch"><link href="css/chunk-d1ec42d4.6070f928.css" rel="prefetch"><link href="css/explainer-dashboard~31ecd969.d570a8d0.css" rel="prefetch"><link href="css/home~f71cff67.89ef0f4e.css" rel="prefetch"><link href="js/about-us~f71cff67.86a36e81.js" rel="prefetch"><link href="js/ai-in-trading-and-retail~f71cff67.2a11bd36.js" rel="prefetch"><link href="js/articles~f71cff67.3eab59e5.js" rel="prefetch"><link href="js/artificial-intelligence-in-supply-chain-management~f71cff67.b9958297.js" rel="prefetch"><link href="js/chunk-21989e4a.c30af962.js" rel="prefetch"><link href="js/chunk-d1ec42d4.3ad09af1.js" rel="prefetch"><link href="js/contact-us~293961c3.8d78ffe2.js" rel="prefetch"><link href="js/explainer-dashboard~31ecd969.8718905d.js" rel="prefetch"><link href="js/foundation~f71cff67.d91d37b5.js" rel="prefetch"><link href="js/home~f71cff67.9b3c5f51.js" rel="prefetch"><link href="js/lorem-ipsum~bf4fa4ce.f5b93105.js" rel="prefetch"><link href="js/ultimate-guide-to-natural-language-processing-courses~f71cff67.8908e706.js" rel="prefetch"><link href="css/app~d0ae3f07.ab899d82.css" rel="preload" as="style"><link href="css/chunk-vendors~253ae210.f9ac28b6.css" rel="preload" as="style"><link href="js/app~d0ae3f07.a5a809c0.js" rel="preload" as="script"><link href="js/chunk-vendors~1c3a2c3f.c86e61ad.js" rel="preload" as="script"><link href="js/chunk-vendors~253ae210.5f9aba88.js" rel="preload" as="script"><link href="js/chunk-vendors~6ed3fd28.44496780.js" rel="preload" as="script"><link href="js/runtime.3f38ea3e.js" rel="preload" as="script"><link href="css/chunk-vendors~253ae210.f9ac28b6.css" rel="stylesheet"><link href="css/app~d0ae3f07.ab899d82.css" rel="stylesheet"><style type="text/css"></style><link href="https://www.googletagmanager.com" rel="preconnect"><script type="text/javascript" async="" src="analytics.js" defer=""></script><script async="" src="gtag/js?id=UA-145601237-1&amp;l=dataLayer" charset="utf-8" defer=""></script><link rel="stylesheet" type="text/css" href="css/explainer-dashboard~31ecd969.d570a8d0.css"><script charset="utf-8" src="js/explainer-dashboard~31ecd969.8718905d.js" defer=""></script><meta data-doro-meta="1" name="title" content="Explainer Dashboard, a tool to answer how the machine learning models works"><meta data-doro-meta="1" name="description" content="Explainer Dashboard is a Python package that makes it easy to quickly interpret a machine learning model. Check out how it works in our article"><meta data-doro-meta="1" property="og:title" content="Explainer Dashboard, a tool to answer how the machine learning models works"><meta data-doro-meta="1" property="og:image" content="https://airev.us/img/title.0ca32258.jpg"><meta data-doro-meta="1" property="og:description" content="Explainer Dashboard is a Python package that makes it easy to quickly interpret a machine learning model. Check out how it works in our article"><meta data-doro-meta="1" property="og:url" content="https://airev.us/explainer-dashboard"><meta data-doro-meta="1" property="twitter:card" content="summary_large_image"><meta data-doro-meta="1" property="twitter:url" content="https://airev.us/explainer-dashboard"><meta data-doro-meta="1" property="twitter:title" content="Explainer Dashboard, a tool to answer how the machine learning models works"><meta data-doro-meta="1" property="twitter:description" content="Explainer Dashboard is a Python package that makes it easy to quickly interpret a machine learning model. Check out how it works in our article"><meta data-doro-meta="1" property="twitter:image" content="https://airev.us/img/title.0ca32258.jpg"><script data-doro-meta="1" type="application/ld+json" defer="">{"@context":"https://schema.org","@type":"Article","name":"Explainer Dashboard, a tool to answer how the machine learning models works","description":"Explainer Dashboard is a Python package that makes it easy to quickly interpret a machine learning model. Check out how it works in our article","image":"https://airev.us/img/title.0ca32258.jpg"}</script><link rel="stylesheet" type="text/css" href="css/about-us~f71cff67.b5ffa400.css"><script charset="utf-8" src="js/about-us~f71cff67.86a36e81.js" defer=""></script></head><body><div id="app" data-server-rendered="true"><section class="el-container is-vertical"><header class="el-header" style="height: 93px;"><div class="main-limiter"><div id="nav"><a href="about-us.html" class="">Team</a><a href="articles.html" class="">News</a><a href="webinars.html" class="">Webinars</a><a href="foundation.html" class="">Foundation</a><a href="https://airev.traffit.com/career/" target="_blank">Careers</a><a href="contact-us.html" class="menu-outline">Contact Us</a></div><div id="logo"><a href="index.htm" class="router-link-active"><div class="doroimage el-image" style="width: 160px;"><img src="img/airev-logo.df94d9a7.svg" loading="auto" class="el-image__inner"></div></a></div></div></header><main class="el-main"><div class="main-limiter margin-bottom-5"><article class="main"><h1>Explainer Dashboard,<br>a tool to answer how the machine learning models works</h1><div class="doroimage el-image inside-of-content" style="width: 700px;"><img src="img/explainer-dashboard.f31149e4.jpg" loading="lazy" class="el-image__inner"></div><p>Recently at work, I was building a very interesting model for catching investment frauds. We were very keen to make sure that our business partner understood why the model made this decision and not another. After all, the model is supposed to support our team to catch criminals! It is crucial that domain experts understand how estimators work and, in case of errors, they let us know to correct the developed model. </p><p> So far I have mainly used the Shap library for explaining a Machine Learning model. This time I found an interesting alternative, which is called Explainer Dashboard! </p><p> In this post, I'll just walk you through the Explainer Dashboard package written by Oege Dijk and show you what it can do to better understand how the model works under the hood. </p><h2>What is Explainer Dashboard?</h2><p> It's a Python package that makes it easy to quickly deploy an interactive dashboard (in the form of a web application) to help in making a machine learning model work and output explainable. It provides interactive charts on model performance, the power of features, the contribution of a feature to individual predictions, "what if" analyses, or visualizations of individual trees! </p><p> Explainer Dashboard customizes the metrics and charts according to the problem the model solves (classification / regression). </p><div class="doroimage el-image round-corners inside-of-content" style="width: 511px;"><img src="img/explainerdashboard_small.578dbaed.gif" loading="lazy" class="el-image__inner"></div><p> Importantly - the library is being constantly developed and more functionalities are being added. Its current main drawback is that it does not yet support deep learning models. </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/1-1.45eeccbe.png" loading="lazy" class="el-image__inner"></div><p> Project’s GitHub: <a href="https://github.com/oegedijk/explainerdashboard" target="_blank">https://github.com/oegedijk/explainerdashboard</a></p><p> An example to tinker around on herokuapp: <a href="https://titanicexplainer.herokuapp.com/" target="_blank">https://titanicexplainer.herokuapp.com/</a></p><p> Okay, based on Titanic's immortal dataset, let's go through specific metrics, features, and graphs. </p><h2>Loading the Explainer Dashboard library</h2><p> You don't need to know AI dashboard building in dash and charting in plotly. The entry threshold to put up your own dashboard is minimal. All you need to do is install the library: </p><div><pre class=" language-bash"><code class=" language-bash">conda install -c conda-forge explainerdashboard</code></pre></div><p> and you can already enjoy loading packages: </p><div><pre class=" language-javascript"><code class=" language-javascript"><span class="token keyword">from</span> explainerdashboard <span class="token keyword">import</span> ClassifierExplainer<span class="token punctuation">,</span> ExplainerDashboard
<span class="token keyword">from</span> explainerdashboard<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> titanic_survive<span class="token punctuation">,</span> titanic_names

<span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgb</code></pre></div><p> We will build a simple model using one of my favorite XGBoost model: </p><div><pre class=" language-javascript"><code class=" language-javascript">X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> <span class="token function">titanic_survive</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
train_names<span class="token punctuation">,</span> test_names <span class="token operator">=</span> <span class="token function">titanic_names</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> xgb<span class="token punctuation">.</span><span class="token function">XGBClassifier</span><span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> max_depth<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token function">fit</span><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></code></pre></div><p> Note that our goal is not to build the best model, but to understand how it works. That's why I'm building without the fun of selecting optimal features and optimizing hyperparameters. </p><p> Now let's add an even nicer description of the characteristics: </p><div><pre class=" language-javascript"><code class=" language-javascript">feature_descriptions <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"Sex"</span><span class="token punctuation">:</span> <span class="token string">"Gender of passenger"</span><span class="token punctuation">,</span>
    <span class="token string">"Gender"</span><span class="token punctuation">:</span> <span class="token string">"Gender of passenger"</span><span class="token punctuation">,</span>
    <span class="token string">"Deck"</span><span class="token punctuation">:</span> <span class="token string">"The deck the passenger had their cabin on"</span><span class="token punctuation">,</span>
    <span class="token string">"PassengerClass"</span><span class="token punctuation">:</span> <span class="token string">"The class of the ticket: 1st, 2nd or 3rd class"</span><span class="token punctuation">,</span>
    <span class="token string">"Fare"</span><span class="token punctuation">:</span> <span class="token string">"The amount of money people paid"</span><span class="token punctuation">,</span>
    <span class="token string">"Embarked"</span><span class="token punctuation">:</span> <span class="token string">"the port where the passenger boarded the Titanic. Either Southampton, Cherbourg or Queenstown"</span><span class="token punctuation">,</span>
    <span class="token string">"Age"</span><span class="token punctuation">:</span> <span class="token string">"Age of the passenger"</span><span class="token punctuation">,</span>
    <span class="token string">"No_of_siblings_plus_spouses_on_board"</span><span class="token punctuation">:</span> <span class="token string">"The sum of the number of siblings plus the number of spouses on board"</span><span class="token punctuation">,</span>
    <span class="token string">"No_of_parents_plus_children_on_board"</span> <span class="token punctuation">:</span> <span class="token string">"The sum of the number of parents plus the number of children on board"</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span></code></pre></div><p> and we can launch the explainer dashboard: </p><div><pre class=" language-javascript"><code class=" language-javascript">explainer <span class="token operator">=</span> <span class="token function">ClassifierExplainer</span><span class="token punctuation">(</span>
  model<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span>
  cats<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Deck'</span><span class="token punctuation">,</span> <span class="token string">'Embarked'</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span><span class="token string">'Gender'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Sex_male'</span><span class="token punctuation">,</span> <span class="token string">'Sex_female'</span><span class="token punctuation">,</span> <span class="token string">'Sex_nan'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  cats_notencoded<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'Embarked'</span><span class="token punctuation">:</span> <span class="token string">'Stowaway'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> # defaults to <span class="token string">'NOT_ENCODED'</span>
  descriptions<span class="token operator">=</span>feature_descriptions<span class="token punctuation">,</span> # adds a table and hover labels to dashboard
  labels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Not survived'</span><span class="token punctuation">,</span> <span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> # defaults to <span class="token punctuation">[</span><span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'1'</span><span class="token punctuation">,</span> etc<span class="token punctuation">]</span>
  idxs <span class="token operator">=</span> test_names<span class="token punctuation">,</span> # defaults to <span class="token constant">X</span><span class="token punctuation">.</span>index
  index_name <span class="token operator">=</span> <span class="token string">"Passenger"</span><span class="token punctuation">,</span> # defaults to <span class="token constant">X</span><span class="token punctuation">.</span>index<span class="token punctuation">.</span>name
  target <span class="token operator">=</span> <span class="token string">"Survival"</span><span class="token punctuation">,</span> # defaults to y<span class="token punctuation">.</span>name
<span class="token punctuation">)</span>

db <span class="token operator">=</span> <span class="token function">ExplainerDashboard</span><span class="token punctuation">(</span>explainer<span class="token punctuation">,</span>
  title<span class="token operator">=</span><span class="token string">"Titanic Explainer"</span><span class="token punctuation">,</span> # defaults to <span class="token string">"Model Explainer"</span>
  shap_interaction<span class="token operator">=</span>True<span class="token punctuation">,</span> # you can <span class="token keyword">switch</span> off tabs <span class="token keyword">with</span> bools
<span class="token punctuation">)</span>
db<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span>port<span class="token operator">=</span><span class="token number">2021</span><span class="token punctuation">)</span></code></pre></div><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/c1.870c9e28.png" loading="lazy" class="el-image__inner"></div><p> Congratulations. Explainer Dashboard set up. Now we can move on to understanding how our model works. </p><h2>Feature Importance</h2><p> Here we will find the answer to the question "which characteristics have the greatest impact on the power of the model?". In the report, we will find information on two metrics: the Permutation Importance and the Shapley Values! </p><h3>Permutation Importance</h3><p> The idea is this: the importance of a feature can be measured by looking at how much the score of a metric of interest (e.g. F1) decreases when we get rid of a particular feature. For such a check, one can remove the feature from the dataset, re-train the estimator and check the result. However, this requires a lot of time, as it involves recalculating the model after removing each feature. And it will be a different model than the one we currently have, so such a test will not answer us 100% whether it will be the same as the initial model. </p><p> Fortunately, someone clever came up with the idea that instead of removing a feature, we can replace it with random noise - the column continues to exist, but no longer contains useful information. This method works if the noise is taken from the same distribution as the original feature values. The easiest way to obtain such noise is to reshuffle the feature values. </p><p> In summary, Permutation Importance is a technique for checking features that can be applied to any fitted estimator if the data is tabular. It is fast and useful for nonlinear and opaque estimators. </p><p> Permutation importance of a feature is defined as the decrease in the model score when the value of a single feature is randomly reshuffled. This procedure breaks the link between the model’s input and the target, so a decrease in the model score indicates how much the model depends on that particular feature. </p><p> A negative value says that after the feature is reshuffled, the power of the model for a given metric increases! So a score close to zero or negative means that the feature adds little to the model. </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/2-1.a3a4c538.png" loading="lazy" class="el-image__inner"></div><h3>Shapley Values</h3><p> Shapley Value is a method of assigning profit between players according to their contribution to the total game. Players cooperate with each other in a coalition and derive some profit from it. Intuitively, it can be said that the Shapley Value tells how much a given player should expect to gain from the total given what, on average, he or she contributes to the game in a given coalition. </p><p> If you are interested in a detailed description of how Shapley value works and is calculated, I invite you to read the following blog article: </p><p><a href="https://christophm.github.io/interpretable-ml-book/shapley.html" target="_blank">https://christophm.github.io/interpretable-ml-book/shapley.html</a></p><h2>Classification Statistics</h2><p>Here we can find general information about the model along with metrics and visualizations showing whether the classification model is performing reasonably.</p><p>At the very top of the tab, we can set a global cut-off for the entire tab. The classification model returns the probability that a given event will occur. If this probability is below the cut-off value, it will take a value of 0, and above it will take a value of 1. For a cut-off threshold set in this way, we will have graphs and metrics calculated in this tab that need a specific class predicted, not the probability itself.</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/3-1.e038ebff.png" loading="lazy" class="el-image__inner"></div><p>Of course, on each chart, we will be able to change this threshold and visualize for ourselves how this would affect the policy of using a particular model.</p><h3>Metrics &amp; Confusion Matrix</h3><p>At the very beginning, you will find all the well-known metrics that are used with classification models, such as:</p><ul><li>Accuracy,</li><li>Precision,</li><li>Recall,</li><li>F1,</li><li>ROC AUC,</li><li>Precision-Recall curve,</li><li>Log Loss.</li></ul><p>In this article, I will not elaborate on each of the metrics. If you don't associate any of them I suggest you take a look at the sklearn documentation, where it is super described: <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" target="_blank">HERE</a>.</p><p>Additionally, you will find Confusion Matrix. Here it is possible to play with the cut-off thresholds to select the optimal level. Obviously, if the data were balanced, a value of 0.5 should be a good starting point. You can then tweak the cutoff threshold up and down to work with the business to see how the model performs and classifies customers.</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/4-1.f7b1b1da.jpg" loading="lazy" class="el-image__inner"></div><h3>Precision Plot</h3><p>Think of it this way: we have a probability score for our model and we sort the observations in ascending order. Then we divide the observations into 7 groups (I set the parameter bin_size = 7, because it looked nice to plot).</p><p>And now we draw a graph, where:</p><ul><li>in blue, with a column graph, we mark the number of observations in a given group,</li><li>in orange with a line graph % of people in a given group with actual first class (in our case, survivors of the Titanic escape),</li><li>with a green line graph % of people in the second class (unlucky people who did not escape from the Titanic).</li></ul><p>Ta-dah:</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/5-1.e8035734.png" loading="lazy" class="el-image__inner"></div><p>In the above graph, I have reached the expected shape of the orange and green lines. As the value of the probability returned by the model (X-axis) increases, the number of survivors increases (orange line), and the number of non-survivors decreases (green line). If the lines were flat all the way through (still around 50%) or intersected every now and then (once higher the orange line and once higher the green line), it would mean that the model can't differentiate customers properly and doesn't work correctly.</p><p>Note that the graph strongly depends on your chosen division method and how many parts you divide it into. See what the shape of the graph looks like for the same model when the number of compartments is significantly increased:</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/6-1.a839e2e0.png" loading="lazy" class="el-image__inner"></div><p>Here you can simply observe that the model distinguishes survivors very well - the orange line shows 100%, which means that in these groups the model did not get it wrong at all. On the other hand, you can see that in the middle between the value of 0.25 and 0.60 the model works middling.</p><p>Do not think that something is wrong with the model, only then take a look at the blue bar. In this case, see that there are 10 people in each group. With such a number of people, 1 person is 10%. Hence, there is nothing to be surprised by such fluctuations and simply aggregate the data more.</p><h3>ROC AUC &amp; PR AUC</h3><p> AUC (Area Under Curve) stands for the area under the curve. So, in order to talk about the ROC AUC or PR AUC score, we must first define what ROC and PR are. </p><p> In a nutshell, an ROC curve is a graph that visualizes the trade-off between a True Positive Rate (Recall)(True Positive Rate) and a False Positive Rate (fall-out) (False Positive Rate). </p><p> It can be interpreted to mean that this metric shows how good the model's prediction ranking is. It tells how likely it is that a randomly selected positive instance has a higher ranking than a randomly selected negative instance. </p><p> PR, on the other hand (Precision-Recall) is a curve that combines Pprecision (precision / PPV) and Rrecall (recall /TPR) in a single visualization. For each threshold, you calculate Precision and Recall and plot them. The higher the curve on the Y axis, the better the performance of the model. Of course, the higher the Rrecall value, the lower the Pprecision. It's worth considering the cut-off point when the OY-axis graph (i.e., Precision) begins to rapidly decline toward a value of 0. </p><p> For this reason, if you care more about the positive class, a better choice is to use PR AUC, which is more sensitive to improvements in the positive class. </p><p> The second important thing is that the ROC AUC can distort the picture if the data are heavily unbalanced. This is because the false-positive rate of highly unbalanced data sets is reduced due to a large number of true-negative results. </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/7-1.b8d516fd.png" loading="lazy" class="el-image__inner"></div><h3>Classification Plot</h3><p>Here you will find a summary of how the population looks below and above the cut-off.</p><p>If you grab the slider and move it left and right, you'll see a cool visualization of how people jump between classes. This will help you explain how the cut-off level will affect the business when it starts using the model and help you choose a parameter.</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/8-1.3437afb8.png" loading="lazy" class="el-image__inner"></div><h3>Cumulative Precision</h3><p>In this graph, we see the percentage of each class if we select the top X % of customers. In the example below, for a cut-off equal to 0.59, you can see that below this value is 22.5% of the population, with survivors accounting for just over 91% and deaths less than 9%.</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/9-1.f135e76c.png" loading="lazy" class="el-image__inner"></div><h3>Lift Curve</h3><p>This is a graph that answers the question of how many times it is better than if we had randomly sampled observations.</p><p>In the example below, you can see that for a cut-off = 0.59 lift is 2.55. Our model for this cutoff indicates a positive class for 93.0%, while a random model at this cut-off would indicate 36.5% (93%/2.5).</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/10-1.5e0d42bc.png" loading="lazy" class="el-image__inner"></div><h2>Individual Prediction</h2><p>This is where the magic happens for the business audience. Because as we sit down with the domain experts we can disenchant them with each specific case, why the model made the decision it did and not another, and what influenced it and to what extent.</p><p>At the top of the tab, we can select a specific observation (e.g. first female passenger).</p><p>Let's see what probability the model returned for her. In this case, you can see that Ms. Florence Briggs has a probability of survival of 90.6%.</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/11-1.4f37881c.png" loading="lazy" class="el-image__inner"></div><p>Let's see why.</p><h3>Partial Dependence Plot (PDP).</h3><p> A partial dependence plot (PDP) shows the marginal effect of a feature on the predicted outcome of a machine learning model. Partial dependence works by marginalizing the output of the machine learning model over the distribution of features from the set so that the function shows the relationship between the features of interest from the set and the predicted output. </p><p> If the feature for which you have calculated PDPs is not correlated with other features, the PDPs perfectly represent how the feature affects the average prediction. In the uncorrelated case, the interpretation is clear: a Partial Dependence Plot shows how the average prediction in your dataset changes when the j-th feature is changed. </p><p> However, it gets more complicated when features are correlated. We may accidentally create new data points in areas of the feature distribution where the actual probability is very low and this can distort the picture a bit. For instance, it's highly unlikely that someone is 2 meters tall, but weighs less than 50 kg - for such feature combination PDP values may have very high uncertainty. </p><p> Let's look at our example. We select the gender feature and see that for our case (blue bold line) if we changed the gender from female to male, the probability of survival would drop from 90.6% to ... 40%. Also in the graph, we have shown the average value for the sample - the bold gray line. </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/12-1.d7795265.png" loading="lazy" class="el-image__inner"></div><p> You can look at each attribute and better understand the performance of the model on the whole. Below, age - you can tell from the graph that it didn't matter that much (in the currently tested model!). </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/13-1.f927a527.png" loading="lazy" class="el-image__inner"></div><h3>Contributions Plot</h3><p>The Contributions Plot works on a similar principle as the PDP except that it shows the contribution of each variable individually and what effect it had on the final outcome. Its main advantage over PDP is that we can plot the impact of more than 2 features on prediction for a particular observation.</p><p>You can see that in our case, the characteristic that contributes the most is gender, and the second most for that person is the price they paid for the ticket.</p><p>In addition, the colors indicate what worked to increase the probability of survival, and in red to decrease the probability of survival.</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/14-1.6bb6d052.png" loading="lazy" class="el-image__inner"></div><p>You have all the results collected below in a table:</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/15-1.a62876a9.png" loading="lazy" class="el-image__inner"></div><h2>What if</h2><p>In my opinion, this is the most interesting section. It shows the same thing we saw in the individual evaluation tab with the difference that we can modify all the features at will and see what effect it had on the model.</p><p>If you sit down with domain experts at this tab they can verify that the model works intuitively and can give interesting input regarding where they think the model is not quite behaving correctly. It is a common technique for discovering a model's fairness and stability.</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/16-1.2f273683.png" loading="lazy" class="el-image__inner"></div><h2>Feature Dependence</h2><p>Here we have two graphs that will show us how the values of given characteristics affect the increase or decrease in probability based on Shapley Values.</p><p> More about Shap itself <a href="https://shap.readthedocs.io/en/latest/index.html" target="_blank">HERE</a>. </p><h3>Shap Summary</h3><p>Here, in the basic version, we get the Shap chart for the features we already know from the first tab. However, it differs in that we can view it in detail, and then it draws us observations. We can select a particular observation and see where it is in the background of the whole. </p><p> In addition, from the graphs, we can see which characteristics increase the probability of survival (those to the right of 0 on the OX axis). Conveniently, we have a colored scale, where blue corresponds to smaller values and red - larger ones). </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/17-1.523e9b09.png" loading="lazy" class="el-image__inner"></div><h3>Shap Dependence</h3><p> Here we can take a closer look at a particular feature of how the distribution looks in terms of Shapley Values. </p><p> Below you can see how strongly gender in the case of the Titanic data affects survival rates: </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/18-1.41c05675.png" loading="lazy" class="el-image__inner"></div><p> An interesting option is that the graph is selected according to the types of data. In the case of the continuous data "Fare", a dot plot is presented instead of a violin plot. </p><p> Note that you can add an additional color based on another feature to see the other variable. </p><p> Below, at first glance, you can't see the dependence of ticket price ("Fare") on gender - the blue and orange colors are mixed. On the other hand, it is immediately transparent that the "Fare" variable itself has an impact on the positive probability of survival - the higher the "Fare" value, the more characteristics have a positive Shapley Value. </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/19-1.9f2ff2da.png" loading="lazy" class="el-image__inner"></div><h2>Decision Trees</h2><p> In this tab, we have visualized how successive trees counted and we can visualize a specific tree. This allows us to closely examine the "guts" of our ensemble model. </p><p> It's worth noting that depending on the model we have, these can be a tad different graphs. </p><p> Below I have shown two examples: </p><p> (a) for the Random Forest, where we have shown each of the 50 trees that gave a probability for a given observation: </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/20-1.58728f2d.png" loading="lazy" class="el-image__inner"></div><p> (b) for XGBoost, where each successive tree is shown: </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/21-1.4f95ba35.png" loading="lazy" class="el-image__inner"></div><p> In addition, for tree algorithms, we can generate a specific tree as it looked: </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/22-1.d153b32a.png" loading="lazy" class="el-image__inner"></div><p>Note: In my case, in order for me to display the tree I had to install the dtreeviz package as described in the installation instructions: <a href="https://github.com/parrt/dtreeviz" target="_blank">https://github.com/parrt/dtreeviz</a>. </p><h2>Regression Statistics</h2><p> Here you will find general information about the regression model, along with metrics and visualizations showing whether the regression model is working reasonably. This tab is present if our model predicts a continuous value, such as product price, growth, or income. </p><p> At the very beginning, you will find any metrics you are familiar with that are used with regression models, such as: </p><ul><li>Root Mean Squared Error,</li><li>Mean Average Error,</li><li>R2 Coefficient.</li></ul><p> Also at a glance, instead of the Confusion Matrix, we have a "Predicted vs Actual" chart. It immediately illustrates how strongly the variable predicted by the model differs from the actual value. </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/23-1.0f9c0c83.png" loading="lazy" class="el-image__inner"></div><p>In our case, we can see that the model predicting the ticket price ("Fare") did much better at predicting low amounts. The blue points depicting the actual values are closer to the predicted value (orange line).</p><p>In addition, you can simply choose a logarithmic scale on the chart.</p><h3>Residuals chart</h3><p>Another graph showing how and where the model is wrong is the residuals chart.</p><p>Residuals are the differences between the actual value and the value predicted by the model. Immediately from the chart, you will see on which values the model underestimates the predicted ticket price and on which it overestimates.</p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/24-1.a1fcd516.png" loading="lazy" class="el-image__inner"></div><h3>Plot vs. feature</h3><p> With this chart, you can get a better understanding of what the distribution looks like for the selected feature: </p><ul><li>predicted values,</li><li>actual values,</li><li>residuals,</li><li>the ratio of residuals,</li><li>the logarithm of the residuals.</li></ul><p> It is worth noting that, depending on the distribution of the selected features, the graph will take different forms: a scatter plot for discrete or a violin plot for continuous. </p><div class="doroimage el-image inside-of-content" style="width: 683px;"><img src="img/25-1.9564f131.png" loading="lazy" class="el-image__inner"></div><h2>Summary of the Explainer Dashboard</h2><p>You can adapt the Explainer Dashboard to suit you, i.e. fire only the appropriate tabs, expose applications in a new window, or launch in Jupiter Notebook.</p><p>We hope you will be able to use this package to present the results of your work.</p><br><p style="font-size: 0.8em;"><i>This article is based on an article by Mirosław Mamczur published on his blog: <a href="https://miroslawmamczur.pl/explainer-dashboard/" target="_blank">miroslawmamczur.pl</a></i> <br><i>Translation and publication on airev.us made with the consent of the author.</i> <br></p></article></div></main><footer class="el-footer" style="padding: 1.618em 20px;"><div class="main-limiter"><div class="el-row"><div class="el-col el-col-12"> AI HARD<br><br> 757 THIRD AVENUE, 17TH FLOOR<br> NEW YORK, NY, 10017 </div><div class="el-col el-col-12" style="text-align: right;"> CONTACT US<br><br> <a href="cdn-cgi/l/email-protection.html" class="__cf_email__" data-cfemail="2b6864657f6a687f6b6a62796e7d057e78">[email&#160;protected]</a><br> +48698121650 </div></div><div style="padding-top: 2.674em; line-height: 30px;"><div style="float: right; opacity: 0.7; height: 30px;"><a href="https://www.facebook.com/AI-Revolution-103702891022983" target="_blank" style="margin: 0px 10px;"><div class="doroimage el-image"><img src="data:image/png;base64,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" loading="lazy" class="el-image__inner"></div></a><a href="https://twitter.com/Marek_Bardonski" target="_blank" style="margin: 0px 10px;"><div class="doroimage el-image"><img src="data:image/png;base64,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" loading="lazy" class="el-image__inner"></div></a><a href="https://www.linkedin.com/company/ai-rev/" target="_blank" style="margin: 0px 10px;"><div class="doroimage el-image"><img src="data:image/png;base64,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" loading="lazy" class="el-image__inner"></div></a></div> Copyright © 2020 AI HARD. All rights reserved. </div></div></footer></section></div><script data-cfasync="false" src="cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script src="js/runtime.3f38ea3e.js" defer=""></script><script src="js/chunk-vendors~253ae210.5f9aba88.js" defer=""></script><script src="js/chunk-vendors~6ed3fd28.44496780.js" defer=""></script><script src="js/chunk-vendors~1c3a2c3f.c86e61ad.js" defer=""></script><script src="js/app~d0ae3f07.a5a809c0.js" defer=""></script><script defer="" src='beacon.min.js' data-cf-beacon='{"token": "da023f7cada2496db0c4b450c7da2ea7"}'></script><script defer="" src="beacon.min.js%20%281%29/v652eace1692a40cfa3763df669d7439c1639079717194" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon='{"rayId":"75bcf2bcd83778fa","version":"2022.8.1","r":1,"token":"8f6e3db4f55045399b4029afffa99790","si":100}' crossorigin="anonymous"></script>
</body></html>